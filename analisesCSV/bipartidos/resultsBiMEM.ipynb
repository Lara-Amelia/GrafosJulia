{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a810ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b70f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'N', 'p', 'M', 'v', 'mean_time', 'se_time', 'mean_chi', 'se_chi', 'peak_mem_mb', 'mean_mem_mb', 'instancia']\n",
      "['a', 'b', 'N', 'p', 'M', 'v', 'mean_time', 'se_time', 'mean_chi', 'se_chi', 'peak_mem_mb', 'mean_mem_mb', 'instancia']\n"
     ]
    }
   ],
   "source": [
    "hash_files = [\n",
    "    \"results_GA_MEM_a100_b100.csv\",\n",
    "    \"results_GA_MEM_a100_b500.csv\"\n",
    "]\n",
    "\n",
    "noHash_files = [\n",
    "    \"results_GA_MEM_noHash_a100_b100.csv\",\n",
    "    \"results_GA_MEM_noHash_a100_b500.csv\"\n",
    "]\n",
    "\n",
    "df_hash = pd.concat([pd.read_csv(f) for f in hash_files], ignore_index=True)\n",
    "df_noHash = pd.concat([pd.read_csv(f) for f in noHash_files], ignore_index=True)\n",
    "\n",
    "print(df_hash.columns.tolist())\n",
    "print(df_hash.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f228186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df para comparação de resultados e obtenção de estatísticas sobre eles\n",
    "df_comp_MEM = pd.merge(df_hash, df_noHash, on=\"instancia\", suffixes=('_hash', '_noHash'))\n",
    "\n",
    "# analisar se há alguma diferença de resultado em termos de qualidade das colorações obtidas\n",
    "df_comp_MEM['diff_chi'] = df_hash['mean_chi'] - df_noHash['mean_chi']\n",
    "\n",
    "# como o que queremos verificar é se o uso da tabela Hash pode gerar redução no tempo de\n",
    "# execução em troca de uso razoável de memória extra, as métricas mais importantes serão o tempo\n",
    "# (com hash deve ser menor), o pico de uso de memória e a memória média (devem ser razoáveis)\n",
    "# (partimos da premissa de que os resultados em qualidade de colorações serão similares ou idênticos,\n",
    "# uma vez que o método é praticamente o mesmo, com alteração somente na avaliação de fitness)\n",
    "df_comp_MEM['diff_tempo'] = df_hash['mean_time'] - df_noHash['mean_time']\n",
    "\n",
    "# Percentual de alteração no tempo de execução\n",
    "# se positivo: o uso de hash demorou mais (pior performance)\n",
    "# se negativo: o uso de hash foi mais rápido (melhor performance) - é o que esperamos\n",
    "df_comp_MEM['time_change_pct'] = ((df_comp_MEM['mean_time_hash'] - df_comp_MEM['mean_time_noHash']) / df_comp_MEM['mean_time_noHash']) * 100\n",
    "\n",
    "df_comp_MEM['speedup'] = df_comp_MEM['mean_time_noHash'] / df_comp_MEM['mean_time_hash']\n",
    "\n",
    "# diferenças em uso de memória (pico e médias)\n",
    "df_comp_MEM['diff_mean_MEM'] = df_hash['mean_mem_mb'] - df_noHash['mean_mem_mb']\n",
    "\n",
    "df_comp_MEM['diff_pico_MEM'] = df_hash['peak_mem_mb'] - df_noHash['peak_mem_mb']\n",
    "\n",
    "# aumento percentual no uso de memória\n",
    "df_comp_MEM['MEM_increase_pct'] = ((df_comp_MEM['mean_mem_mb_hash'] - df_comp_MEM['mean_mem_mb_noHash']) / df_comp_MEM['mean_mem_mb_noHash']) * 100\n",
    "\n",
    "df_comp_MEM['Peak_MEM_increase_pct'] = ((df_comp_MEM['peak_mem_mb_hash'] - df_comp_MEM['peak_mem_mb_noHash']) / df_comp_MEM['peak_mem_mb_noHash']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f92919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Estatísticas de Qualidade (Cores) ---\n",
      "       mean_chi_hash  mean_chi_noHash   diff_chi\n",
      "count      24.000000        24.000000  24.000000\n",
      "mean      258.725000       258.733333  -0.008333\n",
      "std       212.138936       212.274577   0.652698\n",
      "min        36.000000        37.800000  -1.800000\n",
      "25%        91.500000        91.600000  -0.400000\n",
      "50%       176.600000       176.500000   0.000000\n",
      "75%       520.200000       520.150000   0.300000\n",
      "max       592.400000       592.600000   1.200000\n",
      "\n",
      "--- Estatísticas de Performance (Tempo) ---\n",
      "       mean_time_hash  mean_time_noHash  diff_tempo  pct_change_time  \\\n",
      "count       24.000000         24.000000   24.000000        24.000000   \n",
      "mean       326.150129        272.591011   53.559119        -0.473783   \n",
      "std        504.858195        374.292319  186.290113        26.007347   \n",
      "min          1.735520          1.841257 -120.660010       -33.475077   \n",
      "25%         24.453139         30.312488   -8.635924       -14.473584   \n",
      "50%         62.112122         65.108455   -0.927017        -7.031902   \n",
      "75%        496.024726        442.355860    6.529376        11.832684   \n",
      "max       1849.440736       1080.889001  768.551735        71.103669   \n",
      "\n",
      "         speedup  \n",
      "count  24.000000  \n",
      "mean    1.066250  \n",
      "std     0.256908  \n",
      "min     0.584441  \n",
      "25%     0.894260  \n",
      "50%     1.075845  \n",
      "75%     1.170395  \n",
      "max     1.503196  \n",
      "\n",
      "--- Estatísticas de Consumo (Memória) ---\n",
      "       mean_mem_mb_hash  mean_mem_mb_noHash  diff_mean_MEM  pct_increase_mem\n",
      "count         24.000000           24.000000      24.000000         24.000000\n",
      "mean         175.635030          157.994284      17.640746         14.138970\n",
      "std           86.697096           85.203403      40.814177         26.481645\n",
      "min           55.814909           54.491692     -56.283798        -28.562128\n",
      "25%           93.356386          105.149955      -4.072618         -3.239472\n",
      "50%          166.293484          126.031216       8.870728          9.725221\n",
      "75%          246.626228          206.050875      42.613512         26.804674\n",
      "max          367.135950          361.024245     100.012462         73.882664\n",
      "\n",
      "Resumo de Eficiência (Hash vs Sem Hash):\n",
      "Hash mais rápido: 13\n",
      "Tempo equivalente: 0\n",
      "Hash mais lento: 11\n",
      "Instâncias com baixo impacto de memória (<5%): 11\n"
     ]
    }
   ],
   "source": [
    "# qualidade em cores\n",
    "df_comp_MEM['diff_chi'] = df_comp_MEM['mean_chi_hash'] - df_comp_MEM['mean_chi_noHash']\n",
    "\n",
    "# performance em tempo\n",
    "df_comp_MEM['diff_tempo'] = df_comp_MEM['mean_time_hash'] - df_comp_MEM['mean_time_noHash']\n",
    "df_comp_MEM['pct_change_time'] = ((df_comp_MEM['mean_time_hash'] - df_comp_MEM['mean_time_noHash']) / df_comp_MEM['mean_time_noHash']) * 100\n",
    "df_comp_MEM['speedup'] = df_comp_MEM['mean_time_noHash'] / df_comp_MEM['mean_time_hash']\n",
    "# slowdown (contrário do speedup, pode ser melhor para visualização)\n",
    "df_comp_MEM['slowdown_tempo'] = df_comp_MEM['mean_time_hash'] / df_comp_MEM['mean_time_noHash']\n",
    "\n",
    "# consumo de memória\n",
    "df_comp_MEM['diff_mean_MEM'] = df_comp_MEM['mean_mem_mb_hash'] - df_comp_MEM['mean_mem_mb_noHash']\n",
    "df_comp_MEM['pct_increase_mem'] = ((df_comp_MEM['mean_mem_mb_hash'] - df_comp_MEM['mean_mem_mb_noHash']) / df_comp_MEM['mean_mem_mb_noHash']) * 100\n",
    "df_comp_MEM['pct_increase_peak_mem'] = ((df_comp_MEM['peak_mem_mb_hash'] - df_comp_MEM['peak_mem_mb_noHash']) / df_comp_MEM['peak_mem_mb_noHash']) * 100\n",
    "\n",
    "\n",
    "# geração de estatísticas de interesse no df construído\n",
    "stats_qualidade = df_comp_MEM[['mean_chi_hash', 'mean_chi_noHash', 'diff_chi']].describe()\n",
    "stats_tempo = df_comp_MEM[['mean_time_hash', 'mean_time_noHash', 'diff_tempo', 'pct_change_time', 'speedup']].describe()\n",
    "stats_memoria = df_comp_MEM[['mean_mem_mb_hash', 'mean_mem_mb_noHash', 'diff_mean_MEM', 'pct_increase_mem']].describe()\n",
    "\n",
    "print(\"--- Estatísticas de Qualidade (Cores) ---\")\n",
    "print(stats_qualidade)\n",
    "\n",
    "print(\"\\n--- Estatísticas de Performance (Tempo) ---\")\n",
    "print(stats_tempo)\n",
    "\n",
    "print(\"\\n--- Estatísticas de Consumo (Memória) ---\")\n",
    "print(stats_memoria)\n",
    "\n",
    "# resumo de vitórias e eficiência comparativas\n",
    "mais_rapido = (df_comp_MEM['mean_time_hash'] < df_comp_MEM['mean_time_noHash']).sum()\n",
    "tempo_igual = (df_comp_MEM['mean_time_hash'] == df_comp_MEM['mean_time_noHash']).sum()\n",
    "mais_lento = (df_comp_MEM['mean_time_hash'] > df_comp_MEM['mean_time_noHash']).sum()\n",
    "\n",
    "# casos em que o impacto de memória foi baixo (abaixo de 5%)\n",
    "mem_extra_minima = (df_comp_MEM['pct_increase_mem'] < 5).sum() \n",
    "\n",
    "print(f\"\\nResumo de Eficiência (Hash vs Sem Hash):\")\n",
    "print(f\"Hash mais rápido: {mais_rapido}\")\n",
    "print(f\"Tempo equivalente: {tempo_igual}\")\n",
    "print(f\"Hash mais lento: {mais_lento}\")\n",
    "print(f\"Instâncias com baixo impacto de memória (<5%): {mem_extra_minima}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
