{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f5a3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45fffb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['instancia', 'a', 'b', 'c', 'v', 'N', 'M', 'mean_chi', 'se_chi', 'mean_time', 'se_time', 'peak_mem_mb', 'mean_mem_mb']\n",
      "['instancia', 'a', 'b', 'c', 'v', 'N', 'M', 'mean_chi', 'se_chi', 'mean_time', 'se_time', 'peak_mem_mb', 'mean_mem_mb']\n"
     ]
    }
   ],
   "source": [
    "df_hash = pd.read_csv(\"results_GA_ADJ_MEM.csv\")\n",
    "\n",
    "df_noHash = pd.read_csv(\"results_GA_ADJ_MEM_noHash.csv\")\n",
    "\n",
    "print(df_hash.columns.tolist())\n",
    "print(df_noHash.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b57c3519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df para comparação de resultados e obtenção de estatísticas sobre eles\n",
    "df_comp_MEM = pd.merge(df_hash, df_noHash, on=\"instancia\", suffixes=('_hash', '_noHash'))\n",
    "\n",
    "# analisar se há alguma diferença de resultado em termos de qualidade das colorações obtidas\n",
    "df_comp_MEM['diff_chi'] = df_hash['mean_chi'] - df_noHash['mean_chi']\n",
    "\n",
    "# como o que queremos verificar é se o uso da tabela Hash pode gerar redução no tempo de\n",
    "# execução em troca de uso razoável de memória extra, as métricas mais importantes serão o tempo\n",
    "# (com hash deve ser menor), o pico de uso de memória e a memória média (devem ser razoáveis)\n",
    "# (partimos da premissa de que os resultados em qualidade de colorações serão similares ou idênticos,\n",
    "# uma vez que o método é praticamente o mesmo, com alteração somente na avaliação de fitness)\n",
    "df_comp_MEM['diff_tempo'] = df_hash['mean_time'] - df_noHash['mean_time']\n",
    "\n",
    "# Percentual de alteração no tempo de execução\n",
    "# se positivo: o uso de hash demorou mais (pior performance)\n",
    "# se negativo: o uso de hash foi mais rápido (melhor performance) - é o que esperamos\n",
    "df_comp_MEM['time_change_pct'] = ((df_comp_MEM['mean_time_hash'] - df_comp_MEM['mean_time_noHash']) / df_comp_MEM['mean_time_noHash']) * 100\n",
    "\n",
    "df_comp_MEM['speedup'] = df_comp_MEM['mean_time_noHash'] / df_comp_MEM['mean_time_hash']\n",
    "\n",
    "# diferenças em uso de memória (pico e médias)\n",
    "df_comp_MEM['diff_mean_MEM'] = df_hash['mean_mem_mb'] - df_noHash['mean_mem_mb']\n",
    "\n",
    "df_comp_MEM['diff_pico_MEM'] = df_hash['peak_mem_mb'] - df_noHash['peak_mem_mb']\n",
    "\n",
    "# aumento percentual no uso de memória\n",
    "df_comp_MEM['MEM_increase_pct'] = ((df_comp_MEM['mean_mem_mb_hash'] - df_comp_MEM['mean_mem_mb_noHash']) / df_comp_MEM['mean_mem_mb_noHash']) * 100\n",
    "\n",
    "df_comp_MEM['Peak_MEM_increase_pct'] = ((df_comp_MEM['peak_mem_mb_hash'] - df_comp_MEM['peak_mem_mb_noHash']) / df_comp_MEM['peak_mem_mb_noHash']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c686c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Estatísticas de Qualidade (Cores) ---\n",
      "       mean_chi_hash  mean_chi_noHash    diff_chi\n",
      "count     189.000000       189.000000  189.000000\n",
      "mean       77.620106        77.571429    0.048677\n",
      "std        27.453919        27.365521    0.807782\n",
      "min        12.000000        12.000000   -2.600000\n",
      "25%        59.800000        59.800000   -0.200000\n",
      "50%        81.000000        80.600000    0.000000\n",
      "75%        99.200000        99.200000    0.400000\n",
      "max       133.800000       133.800000    3.200000\n",
      "\n",
      "--- Estatísticas de Performance (Tempo) ---\n",
      "       mean_time_hash  mean_time_noHash  diff_tempo  pct_change_time  \\\n",
      "count      189.000000        189.000000  189.000000       189.000000   \n",
      "mean        33.690430         34.361619   -0.671189         5.329396   \n",
      "std         48.879356         52.805209   19.110463        37.302902   \n",
      "min          0.001330          0.001420 -117.234340       -71.098682   \n",
      "25%          1.579260          1.373560   -2.921640       -15.996422   \n",
      "50%         13.907230         12.659730   -0.001540        -2.690486   \n",
      "75%         39.977430         44.510730    2.451320        17.079443   \n",
      "max        239.231550        303.688650   85.091130       213.244616   \n",
      "\n",
      "          speedup  \n",
      "count  189.000000  \n",
      "mean     1.057984  \n",
      "std      0.365579  \n",
      "min      0.319239  \n",
      "25%      0.854121  \n",
      "50%      1.027649  \n",
      "75%      1.190425  \n",
      "max      3.460050  \n",
      "\n",
      "--- Estatísticas de Consumo (Memória) ---\n",
      "       mean_mem_mb_hash  mean_mem_mb_noHash  diff_mean_MEM  pct_increase_mem\n",
      "count        189.000000          189.000000     189.000000        189.000000\n",
      "mean         276.042165          268.319070       7.723095          7.856713\n",
      "std          235.286553          241.202311     108.375303         29.688199\n",
      "min           26.534337           26.421002    -452.252609        -59.224706\n",
      "25%           92.711673           83.014386     -24.525191        -12.352480\n",
      "50%          220.289149          194.014163       2.869327          2.389603\n",
      "75%          381.556195          395.833417      41.778807         22.452519\n",
      "max         1023.216515         1292.281471     368.542427        115.709291\n",
      "\n",
      "Resumo de Eficiência (Hash vs Sem Hash):\n",
      "Hash mais rápido: 107\n",
      "Tempo equivalente: 0\n",
      "Hash mais lento: 82\n",
      "Instâncias com baixo impacto de memória (<5%): 107\n"
     ]
    }
   ],
   "source": [
    "# qualidade em cores\n",
    "df_comp_MEM['diff_chi'] = df_comp_MEM['mean_chi_hash'] - df_comp_MEM['mean_chi_noHash']\n",
    "\n",
    "# performance em tempo\n",
    "df_comp_MEM['diff_tempo'] = df_comp_MEM['mean_time_hash'] - df_comp_MEM['mean_time_noHash']\n",
    "df_comp_MEM['pct_change_time'] = ((df_comp_MEM['mean_time_hash'] - df_comp_MEM['mean_time_noHash']) / df_comp_MEM['mean_time_noHash']) * 100\n",
    "df_comp_MEM['speedup'] = df_comp_MEM['mean_time_noHash'] / df_comp_MEM['mean_time_hash']\n",
    "# slowdown (contrário do speedup, pode ser melhor para visualização)\n",
    "df_comp_MEM['slowdown_tempo'] = df_comp_MEM['mean_time_hash'] / df_comp_MEM['mean_time_noHash']\n",
    "\n",
    "# consumo de memória\n",
    "df_comp_MEM['diff_mean_MEM'] = df_comp_MEM['mean_mem_mb_hash'] - df_comp_MEM['mean_mem_mb_noHash']\n",
    "df_comp_MEM['pct_increase_mem'] = ((df_comp_MEM['mean_mem_mb_hash'] - df_comp_MEM['mean_mem_mb_noHash']) / df_comp_MEM['mean_mem_mb_noHash']) * 100\n",
    "df_comp_MEM['pct_increase_peak_mem'] = ((df_comp_MEM['peak_mem_mb_hash'] - df_comp_MEM['peak_mem_mb_noHash']) / df_comp_MEM['peak_mem_mb_noHash']) * 100\n",
    "\n",
    "\n",
    "# geração de estatísticas de interesse no df construído\n",
    "stats_qualidade = df_comp_MEM[['mean_chi_hash', 'mean_chi_noHash', 'diff_chi']].describe()\n",
    "stats_tempo = df_comp_MEM[['mean_time_hash', 'mean_time_noHash', 'diff_tempo', 'pct_change_time', 'speedup']].describe()\n",
    "stats_memoria = df_comp_MEM[['mean_mem_mb_hash', 'mean_mem_mb_noHash', 'diff_mean_MEM', 'pct_increase_mem']].describe()\n",
    "\n",
    "print(\"--- Estatísticas de Qualidade (Cores) ---\")\n",
    "print(stats_qualidade)\n",
    "\n",
    "print(\"\\n--- Estatísticas de Performance (Tempo) ---\")\n",
    "print(stats_tempo)\n",
    "\n",
    "print(\"\\n--- Estatísticas de Consumo (Memória) ---\")\n",
    "print(stats_memoria)\n",
    "\n",
    "# resumo de vitórias e eficiência comparativas\n",
    "mais_rapido = (df_comp_MEM['mean_time_hash'] < df_comp_MEM['mean_time_noHash']).sum()\n",
    "tempo_igual = (df_comp_MEM['mean_time_hash'] == df_comp_MEM['mean_time_noHash']).sum()\n",
    "mais_lento = (df_comp_MEM['mean_time_hash'] > df_comp_MEM['mean_time_noHash']).sum()\n",
    "\n",
    "# casos em que o impacto de memória foi baixo (abaixo de 5%)\n",
    "mem_extra_minima = (df_comp_MEM['pct_increase_mem'] < 5).sum() \n",
    "\n",
    "print(f\"\\nResumo de Eficiência (Hash vs Sem Hash):\")\n",
    "print(f\"Hash mais rápido: {mais_rapido}\")\n",
    "print(f\"Tempo equivalente: {tempo_igual}\")\n",
    "print(f\"Hash mais lento: {mais_lento}\")\n",
    "print(f\"Instâncias com baixo impacto de memória (<5%): {mem_extra_minima}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
